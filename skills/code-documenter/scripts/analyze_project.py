#!/usr/bin/env python3
"""
é¡¹ç›®åˆ†æè„šæœ¬ - æ‰«æé¡¹ç›®ç»“æ„å¹¶æå–å…³é”®ä¿¡æ¯
"""

import os
import ast
import sys
import io
from pathlib import Path
from typing import Dict, List, Any
import json

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.files_info = []
        self.imports_graph = {}
        self.modules = {}

    def analyze(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„é¡¹ç›®åˆ†æ"""
        print(f"ğŸ” åˆ†æé¡¹ç›®: {self.project_root}")

        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = self._find_python_files()
        print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in python_files:
            self._analyze_file(file_path)

        # æ„å»ºä¾èµ–å…³ç³»å›¾
        self._build_dependency_graph()

        # è¯†åˆ«ä¸»è¦å…¥å£ç‚¹
        entry_points = self._identify_entry_points()

        return {
            "project_root": str(self.project_root),
            "total_files": len(python_files),
            "modules": self.modules,
            "imports_graph": self.imports_graph,
            "entry_points": entry_points,
            "files": self.files_info
        }

    def _find_python_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
        exclude_dirs = {'.git', '__pycache__', 'venv', '.venv', 'node_modules',
                       'dist', 'build', '.tox', '.pytest_cache'}

        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # è¿‡æ»¤æ‰ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith('.')]

            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)

        return python_files

    def _analyze_file(self, file_path: Path):
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                tree = ast.parse(content, filename=str(file_path))

            relative_path = file_path.relative_to(self.project_root)
            module_name = str(relative_path.with_suffix('')).replace(os.sep, '.')

            # æå–ç±»å’Œå‡½æ•°
            classes = []
            functions = []
            imports = []

            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append({
                        "name": node.name,
                        "methods": [m.name for m in node.body if isinstance(m, ast.FunctionDef)],
                        "docstring": ast.get_docstring(node)
                    })
                elif isinstance(node, ast.FunctionDef):
                    # åªè®°å½•é¡¶å±‚å‡½æ•°
                    if hasattr(tree, 'body') and node in tree.body:
                        functions.append({
                            "name": node.name,
                            "docstring": ast.get_docstring(node)
                        })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    for alias in node.names:
                        imports.append(alias.name)

            self.files_info.append({
                "path": str(relative_path),
                "module": module_name,
                "classes": classes,
                "functions": functions,
                "imports": imports
            })

            self.modules[module_name] = {
                "path": str(relative_path),
                "classes": classes,
                "functions": functions,
                "imports": imports
            }

        except SyntaxError as e:
            print(f"âš ï¸  è¯­æ³•é”™è¯¯ {file_path}: {e}")
        except Exception as e:
            print(f"âš ï¸  åˆ†æé”™è¯¯ {file_path}: {e}")

    def _build_dependency_graph(self):
        """æ„å»ºæ¨¡å—ä¾èµ–å…³ç³»å›¾"""
        for module_name, module_info in self.modules.items():
            self.imports_graph[module_name] = [
                imp for imp in module_info["imports"]
                if not imp.startswith('.')
            ]

    def _identify_entry_points(self) -> List[str]:
        """è¯†åˆ«é¡¹ç›®å…¥å£ç‚¹"""
        entry_points = []

        # æŸ¥æ‰¾å¸¸è§çš„å…¥å£æ–‡ä»¶
        common_entries = ['__main__.py', 'main.py', 'app.py', 'run.py']
        for entry in common_entries:
            for module in self.modules:
                if module.endswith(entry.replace('.py', '')):
                    entry_points.append(module)

        # æŸ¥æ‰¾ if __name__ == '__main__' å—
        for file_info in self.files_info:
            file_path = self.project_root / file_info["path"]
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if '__main__' in content:
                        entry_points.append(file_info["module"])
            except:
                pass

        return entry_points


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze_project.py <project-root>")
        sys.exit(1)

    project_root = sys.argv[1]
    analyzer = ProjectAnalyzer(project_root)
    result = analyzer.analyze()

    # è¾“å‡ºç»“æœ
    output_file = Path(project_root) / '.claude' / 'project_analysis.json'
    output_file.parent.mkdir(exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   - æ€»æ–‡ä»¶æ•°: {result['total_files']}")
    print(f"   - æ¨¡å—æ•°: {len(result['modules'])}")
    print(f"   - å…¥å£ç‚¹: {', '.join(result['entry_points']) or 'æœªæ£€æµ‹åˆ°'}")


if __name__ == '__main__':
    main()
